<img src="https://raw.githubusercontent.com/hershyz/oracle/main/assets/oracle.png">
<p><i>A Novel Implementation of LiDAR Mesh Classification and Image Classifiers In Assistive Technology for the Visually Impaired.</i></p>

<br>

<h3>Background Information</h3>
<p>
253 million people worldwide including 20.6 million Americans are visually impaired. Research acknowledges that 42% of these visually impaired people have trouble navigating everyday objects in their environments.
</p>

<br>

<h3>Goal</h3>
<p>
To alleviate the stressors experienced by the visually impaired when traversing unfamiliar environments by leveraging LiDAR mesh classifications and supplemental image classifiers to non-intrusively relay sufficient descriptions of the surroundings to the user.
</p>

<br>

<h3>How it Works</h3>
<ul>
  <li>We used the LiDAR sensor (iPhone 12 Pro) to classify objects that were relatively geometrically simple from a depthmap. The LiDAR sensor doubled as a distance measuring device, capable of measuring object distances up to 5 meters.</li>
  <li>For objects that were more geometrically complex, we used Swift's CoreML library for image classifications.</li>
  <li>Finally, we used Swift's AVFoundation library to non-intrusively relay descriptions of surroundings to the user.</li>
</ul>

<br>

<h3>Results</h3>
<img src="https://raw.githubusercontent.com/hershyz/oracle/main/assets/graph.png">
<img src="https://raw.githubusercontent.com/hershyz/oracle/main/assets/accuracies.png">
<img src="https://raw.githubusercontent.com/hershyz/oracle/main/assets/distances.png">

<br>

<h3>Partners</h3>
<ul>
  <li><a href="https://github.com/sam-shridhar1950f">Samarth Shridhar</a></li>
  <li><a href="https://github.com/JBPrew">Jack Prewitt</a></li>
</ul>

<br>

<h3>Honors & Awards</h3>
<ul>
  <li>1st Place in the Georgia Junior Science & Humanities Symposium</li>
  <li>1st Place in the GSMST Science & Engineering Fair</li>
</ul>
